# 软件架构与设计模式

服务器

<极客时间>

# **分布式**

### 总结

分布式场景的三大算法: 集中式算法(协调者broker), 分布式算法(同意), 循环令牌算法(回路循环)

## 基本定义



## 00开篇词 | 四纵四横，带你透彻理解分布式技术

在众多计算机技术当中，分布式技术无疑是最璀璨的明珠之一。毫不夸张地说，没有分布式技术就没有互联网，也就没有现在的阿里巴巴、腾讯、亚马逊、Facebook、谷歌等科技巨头，更不会有以信息技术为核心的、对人类历史产生巨大变革的第三次工业革命。万维网、Email、DNS 等，都是分布式系统的典型代表。

随着分布式技术的不断发展，它也早已不再局限于传统的互联网等应用场景。在今年的两会期间，全国政协委员、360 董事长周鸿祎更是大唱 I’M ABCDE 字母歌。**IMABCDE 这 7 个字母所代表的 IoT 物联网、Mobile 移动计算、AI 人工智能、Blockchain 区块链、Cloud 云计算、Data 大数据、Edge 边缘计算，也无不都是以分布式技术为基石。**

无疑，**谁更好地掌握了分布式技术，谁就更容易在新一轮技术浪潮中获得主动。**在全球经济增速趋缓的大背景下，与许多应用业务大量裁人形成鲜明对比的是，各大巨头的中间件团队、实验室等基础部门，依然在大规模地招兵买马。随着业务扩展，以及 IMABCDE 等新兴技术领域的布局，分布式技术人才已然成为巨头们争夺的焦点。

**一方面是各大厂商的求贤若渴，一方面是分布式专业技术人才的一将难求。**在多年的面试中，我经常能体会到，有些面试者确实非常积极主动，但他们表现出来的水平却无法通过面试。分布式技术人才市场的供应与需求，俨然一首冰与火之歌。

2007 年，我在西安电子科技大学攻读博士期间，就开始研究并行与分布式计算；毕业后，在 IBM 做过 HPC 大规模负载管理系统 LSF 相关的设计和研发工作，在华为负责过分布式 IoT 相关项目的架构设计，以及电信级业务微服务框架、函数服务框架的设计工作，也从事过区块链相关的研究工作。现在，我在智载云帆负责技术体系的构建，专注于无服务器 Serverless 的架构实践。

从我深入研究分布式技术这十多年的经验来看，分布式技术概念繁多、知识庞杂、新兴技术层出不穷，令许多新手望而却步，而许多有一定年限工作经验的老手，虽然也能对一些概念滔滔不绝，但追问到实质性问题就变得磕磕巴巴，顾左右而言它。比如：

- 各种分布式概念、名词学了一大堆，但经常张冠李戴，傻傻分不清楚；
- 做了多年技术，也参与了很多分布式技术实践，却无法回答工作中各种分布式技术、组件、框架选型背后的根源；
- 在一个分布式技术配套的典型场景往往能驾轻就熟，但一旦稍微变更考察业务场景、业务目标后，就变得毫无头绪。

究其原因，主要是**知识碎片化、不成体系、见树不见林。**如果再追究更深层次的原因，那无外乎就是两点：

- **在计算机学科课程设置中，分布式技术尴尬如同中小学中的性教育，重要但不受重视。**鲜有高校在计算机本科专业中设置分布式课程，即便是有些高校在研究生教育中设置了相关课程，也是如同高手过招点到为止。
- **信息碎片化与信息孤立。**在信息泛滥的信息时代，各种经典教材、最新文章自然是唾手可得。但，教材固然经典但严谨有余浅出不够，最重要的是没有与时下最新的场景相结合，一方面是因为教材“年久失修”，另一方面确实是因为分布式领域新技术推出的速度令人叹为观止；而网上的各种技术文章虽然多，却鲜有体系化的说明，一个个概念如同一座座信息孤岛。**如果不能体系化地理解这些概念，何谈掌握，更谈不上真正地去综合运用这些知识了。**

因为工作太忙，这些年我整体而系统的输出比较少。偶然一次听到任正非的讲话，他提到了基础教育、孩子是一个社会的未来，这让我感触良多。我想，如果说一个社会的未来，离不开朝气蓬勃的孩子们，那么**一个行业的兴盛，同样也离不开一个广泛的从业者基础。**而我如果能做好分布式通识课这样的一个专栏，既可以对自己这些年的经验做一次系统梳理，温故而知新，又能帮助更多的人系统理解并掌握分布式核心技术，为整个行业的兴盛略尽绵薄之力，何乐而不为呢？

其实，在工作、面试、演讲等多种场合，也经常会有人问我：“聂博士，分布式领域的新概念繁多、各种框架五花八门、各种组件层出不穷，应该如何应对啊？”我回答说：“其实你已经有答案了。”

看着他们满脸疑惑，我笑着问：“RISC 芯片，程序设计中的封装、继承，还有现在提倡的中台战略，它们都在做一件什么事情呢？”他们答道：“莫非是重用？”

我说：“是的，**既然指令可以重用，代码可以重用，技术、业务、数据等都可以重用，为什么知识体系不可以呢？学好分布式通识课，掌握了分布式的核心技术、体系，你就会发现很多新技术、新框架、新组件只不过是‘新瓶装旧酒’，将分布式核心技术进行了再包装、再组合，至多也就是做了一点延伸而已。”**

那么，分布式通识课究竟该如何学呢？在接下来的三个月时间里，我会遵循以下 4 个思路带着你一起学习。

第一，分布式技术错综复杂，各种技术相互耦合，确实无法简单地像网络等技术一样划分层次，所以我会结合自己多年的积累和思考，首先为你梳理出一个脉络清晰、**四纵四横**的分布式核心技术知识体系，然后从这个纵横的技术体系中抽取最核心、最普适的技术思想以及概念，结合各种适用场景一一解析。这样的设计，旨在帮助你找到核心知识点，并将这些知识点联系起来，快速形成分布式核心技术的知识网络，从而形成自己的技术判断力，进而规划出自己的技术路线。

第二，从一个熟知的事物出发，进行浅出的讲解，帮助你从已有知识体系扩展到新的知识体系，从而迅速、牢固地掌握分布式技术的核心知识点。

第三，透过表象深入讲解技术本质，而不是 case by case 地讲解，帮助你知其然并知其所以然，真正做到理解与运用时的举一反三。

第四，针对同一分布式问题的不同方法，从多维度、多角度进行对比、分析，方便你在工作中灵活选型，避免重复“造轮子”。你甚至可以综合权衡各种方法的优缺点，提炼发明出新的方法，最终做到活学活用。

讲到这里，你是不是也有点摩拳擦掌、跃跃欲试了呢？“分布式世界这么大，我要去看看！”别慌，请先看完这份技术地图。

![](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/20210426194145.jpg)

首先，按照业务的架构层次栈，我自底向上按照资源、通信、数据与计算的维度，梳理出了 4 个技术层次：分布式资源池化、分布式通信、分布式数据存储与管理、分布式计算。这样的划分符合业务架构设计的一般规律，即**“在一定资源上，进行一定通信，通过一定计算，完成一定数据的加工和处理，从而对外提供特定的服务”。**另一方面，这样的划分也整合了零散的知识点，具有完备性。

既然横向的 4 个层次都已经完备了，那为什么又多出了 4 个纵向的技术呢？如果我们把横向的 4 个层次比作派生类的话，那么纵向的 4 条技术线应该是它们的基类。因为，在分布式环境下，无论是资源、通信、数据还是计算，都需要去解决协同、调度、追踪高可用，还有部署的问题。因此，我从横向的技术层次中，提炼出分布式协同、分布式调度、分布式追踪与高可用、分布式部署 4 个纵向技术线。由于分布式追踪、分布式部署虽属于支撑技术，但并不会影响业务的构成，因此我不会在本专栏中进行讲解。

最后，如果说现在分布式领域里各种包装出来的、五花八门的新技术，像是令人高不可攀的女神、男神的话，那么这个分布式通识课程中所提炼出来的体系和核心知识点无疑就是女神、男神素颜的样子。我想说，等你**看尽素颜，无论是女神、男神也好，还是各种高大上的技术也好，也就不会觉得那么高不可攀了。**

既然你已经看到了这里，相信你也看到了学习分布式技术知识的迫切需求，那么不妨请你在留言区做个自我介绍，给我说说你的困惑，也说说你想通过这个专栏收获些什么，这样我后续也可以根据你的情况进行有针对性的讲解。

我是聂鹏程，今天的内容就到这里了，我们下一讲再会。

## 01 | 分布式缘何而起：从单兵，到游击队，到集团军

你好，我是聂鹏程。这是专栏的第一篇文章，我们先来聊聊什么是分布式。

与其直接用些抽象、晦涩的技术名词去给分布式下一个定义，还不如从理解分布式的发展驱动因素开始，我们一起去探寻它的本质，自然而然地也就清楚它的定义了。

在今天这篇文章中，我将带你了解分布式的起源，是如何从单台计算机发展到分布式的，进而帮助你深入理解什么是分布式。为了方便你更好地理解这个演进过程，我将不考虑多核、多处理器的情况，假定每台计算机都是单核、单处理器的。

### 分布式起源

### 单兵模式：单机模式

1946 年情人节发布的 ENIAC 是世界上的第一台通用计算机，它占地 170 平米重达 30 吨，每秒可进行 5000 次加法或者 400 次乘法运算，标志着单机模式的开始。

所谓**单机模式**是指，所有应用程序和数据均部署在一台电脑或服务器上，由一台计算机完成所有的处理。

以铁路售票系统为例，铁路售票系统包括用户管理、火车票管理和订单管理等模块，数据包括用户数据、火车票数据和订单数据等，如果使用单机模式，那么所有的模块和数据均会部署在同一台计算机上，也就是说数据存储、请求处理均由该计算机完成。这种模式的好处是功能、代码和数据集中，便于维护、管理和执行。

单机模式的示意图，如下所示：

![](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/20210426194151.jpg)

这里需要注意的是，**本文的所有示意图中，紫色虚线表示在一台计算机内。**

事物均有两面性，我们再来看看单机模式的缺点。单个计算机的处理能力取决于 CPU 和内存等，但硬件的发展速度和性能是有限的，而且升级硬件的性价比也是我们要考虑的，由此决定了 CPU 和内存等硬件的性能将成为单机模式的瓶颈。

你有没有发现，单机模式和单兵作战模式非常相似，单台计算机能力再强，就好比特种兵以一敌百，但终归能力有限。此外，将所有任务都交给一台计算机，也会存在将所有鸡蛋放到一个篮子里的风险，也就是单点失效问题。

归纳一下，单机模式的主要问题是：**性能受限、存在单点失效问题。**

### 游击队模式：数据并行或数据分布式

既然单机模式存在性能和可用性的问题。那么，有没有什么更好的计算模式呢？答案是肯定的。

为解决单机模式的问题，并行计算得到了发展，进而出现了数据并行（也叫作数据分布式）模式。**并行计算**采用消息共享模式使用多台计算机并行运行或执行多项任务，核心原理是每台计算机上执行相同的程序，将数据进行拆分放到不同的计算机上进行计算。

请注意，并行计算强调的是对数据进行拆分，任务程序在每台机器上运行。要达到这个目的，我们必须首先把单机模式中的应用和数据分离，才可能实现对数据的拆分。这里的应用就是执行任务的程序，任务就是提交的请求。以铁路售票系统为例，运行在服务器上的用户管理、火车票管理和订单管理等程序就是应用，用户提交的查询火车票、购买火车票的请求就是任务。

在单机模式中，应用和数据均在一台计算机或服务器上，要实现数据的并行，首先必须将应用和数据分离以便将应用部署到不同的计算机或服务器上；然后，对同类型的数据进行拆分，比方说，不同计算机或服务器上的应用可以到不同的数据库上获取数据执行任务。

以铁路售票系统的数据并行为例，主要包括两个步骤，如下所示：

**第一步**，将应用与数据分离，分别部署到不同的服务器上：

![](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/20210426194155.jpg)

**第二步**，对数据进行拆分，比如把同一类型的数据拆分到两个甚至更多的数据库中，这样应用服务器上的任务就可以针对不同数据并行执行了。

对于铁路售票系统来说，根据线路将用户、火车票和订单数据拆分到不同的数据库中，部署到不同的服务器上，比如京藏线的数据放在数据库服务器 1 上的数据库中，沪深线的数据放在数据库服务器 2 上的数据库中。



![](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/20210426194159.jpg)

需要注意的是，为了更好地帮助你理解这个数据拆分的过程，我在这里选择拆分数据库的方式进行讲解。由于数据库服务器本身的并发特性，因此你也可以根据你的业务情况进行选择，比方说所有业务服务器共用一个数据库服务器，而不一定真的需要去进行数据库拆分。

可以看出，在数据并行或数据分布式模式中，每台计算机都是全量地从头到尾一条龙地执行一个程序，就像一个全能的铁道游击队战士。所以，你也可以将这种模式形象地理解成游击队模式，就和铁道游击队插曲的歌词有点类似：“我们扒飞车那个搞机枪，撞火车那个炸桥梁……”

这种模式的好处是，可以利用多台计算机并行处理多个请求，使得我们可以在相同的时间内完成更多的请求处理，解决了单机模式的计算效率瓶颈问题。但这种模式仍然存在如下几个问题，在实际应用中，我们需要对其进行相应的优化：

- 相同的应用部署到不同的服务器上，当大量用户请求过来时，如何能比较均衡地转发到不同的应用服务器上呢？解决这个问题的方法是设计一个负载均衡器，我会在”分布式高可靠“模块与你讲述负载均衡的相关原理。
- 当请求量较大时，对数据库的频繁读写操作，使得数据库的 IO 访问成为瓶颈。解决这个问题的方式是读写分离，读数据库只接收读请求，写数据库只接收写请求，当然读写数据库之间要进行数据同步，以保证数据一致性。
- 当有些数据成为热点数据时，会导致数据库访问频繁，压力增大。解决这个问题的方法是引入缓存机制，将热点数据加载到缓存中，一方面可以减轻数据库的压力，另一方面也可以提升查询效率。

从上面介绍可以看出，数据并行模式实现了多请求并行处理，但如果单个请求特别复杂，比方说需要几天甚至一周时间的时候，数据并行模式的整体计算效率还是不够高。

由此可见，数据并行模式的主要问题是：**对提升单个任务的执行性能及降低时延无效。**

#### 集团军模式：任务并行或任务分布式

那么，有没有办法可以提高单个任务的执行性能，或者缩短单个任务的执行时间呢？答案是肯定的。任务并行（也叫作任务分布式）就是为解决这个问题而生的。那什么是任务并行呢？

任务并行指的是，将单个复杂的任务拆分为多个子任务，从而使得多个子任务可以在不同的计算机上并行执行。

我们仍以铁路售票系统为例，任务并行首先是对应用进行拆分，比如按照领域模型将用户管理、火车票管理、订单管理拆分成多个子系统分别运行在不同的计算机或服务器上。换句话说，原本包括用户管理、火车票管理和订单管理的一个复杂任务，被拆分成了多个子任务在不同计算机或服务器上执行，如下图所示：

![](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/20210426194205.jpg)

可以看出，任务并行模式完成一项复杂任务主要有两个核心步骤：首先将单任务拆分成多个子任务，然后让多个子任务并行执行。这种模式和集团军模式很像，任务拆分者对应领导者，不同子系统对应不同兵种，不同子程序执行不同任务就像不同的兵种执行不同的命令一样，并且运行相同子系统或子任务的计算机又可以组成一个兵团。

在集团军模式中，由于多个子任务可以在多台计算机上运行，因此通过将同一任务待处理的数据分散到多个计算机上，在这些计算机上同时进行处理，就可以加快任务执行的速度。因为，只要一个复杂任务拆分出的任意子任务执行时间变短了，那么这个任务的整体执行时间就变短了。

当然，nothing is perfect。**集团军模式在提供了更好的性能、扩展性、可维护性的同时，也带来了设计上的复杂性问题**，毕竟对一个大型业务的拆分也是一个难题。不过，对于大型业务来讲，从长远收益来看，这个短期的设计阵痛是值得的。这也是许多大型互联网公司、高性能计算机构等竞相对业务进行拆分以及重构的一个重要原因。

### 分布式是什么？

讲了半天，那到底什么是分布式呢？

**总结一下，分布式其实就是将相同或相关的程序运行在多台计算机上，从而实现特定目标的一种计算方式。**

从这个定义来看，数据并行、任务并行其实都可以算作是分布式的一种形态。从这些计算方式的演变中不难看出，**产生分布式的最主要驱动力量，是我们对于性能、可用性及可扩展性的不懈追求。**

### 总结

在今天这篇文章中，我和你分享了分布式的起源，即从单机模式到数据并行（也叫作数据分布式）模式，再到任务并行（也叫作任务分布式）模式。

单机模式指的是，所有业务和数据均部署到同一台机器上。这种模式的好处是功能、代码和数据集中，便于维护、管理和执行，但计算效率是瓶颈。也就是说单机模式性能受限，也存在单点失效的问题。

数据并行（也叫作数据分布式）模式指的是，对数据进行拆分，利用多台计算机并行执行多个相同任务，通过在相同的时间内完成多个相同任务，从而缩短所有任务的总体执行时间，但对提升单个任务的执行性能及降低时延无效。

任务并行（也叫作任务分布式）模式指的是，单任务拆分成多个子任务，多个子任务并行执行，只要一个复杂任务中的任意子任务的执行时间变短了，那么这个业务的整体执行时间也就变短了。该模式在提高性能、扩展性、可维护性等的同时，也带来了设计上的复杂性问题，比如复杂任务的拆分。

在数据并行和任务并行这两个模式的使用上，用户通常会比较疑惑，到底是采用数据并行还是任务并行呢？一个简单的原则就是：任务执行时间短，数据规模大、类型相同且无依赖，则可采用数据并行；如果任务复杂、执行时间长，且任务可拆分为多个子任务，则考虑任务并行。在实际业务中，通常是这两种模式并用。赶紧行动起来，去分析一下你的业务到底应该采用哪种分布式模式吧，加油！

## 02 | 分布式系统的指标：啥是分布式的三围

你好，我是聂鹏程。

在上一篇文章中，通过对分布式发展历程的学习，我们对分布式技术有了一个整体印象。接下来，我们就再来看看可以用哪些指标去具体地衡量一个分布式系统。如果你已经对分布式系统的指标了解得很清楚了，可以直接跳过这篇文章，学习下一讲的内容。

### 分布式系统的指标

从分布式技术的起源可以看出，分布式系统的出现就是为了用廉价的、普通的机器解决单个计算机处理复杂、大规模数据和任务时存在的性能问题、资源瓶颈问题，以及可用性和可扩展性问题。换句话说，分布式的目的是**用更多的机器，处理更多的数据和更复杂的任务。**

由此可以看出，**性能、资源、可用性和可扩展性**是分布式系统的重要指标。没错，它们就是分布式系统的“三围”。接下来，我们一起来看看这几个指标吧。

### 性能（Performance）

性能指标，主要用于衡量一个系统处理各种任务的能力。无论是分布式系统还是单机系统，都会对性能有所要求。

不同的系统、服务要达成的目的不同，关注的性能自然也不尽相同，甚至是相互矛盾。常见的性能指标，包括吞吐量（Throughput）、响应时间（Response Time）和完成时间（Turnaround Time）。

**吞吐量**指的是，系统在一定时间内可以处理的任务数。这个指标可以非常直接地体现一个系统的性能，就好比在客户非常多的情况下，要评判一个银行柜台职员的办事效率，你可以统计一下他在 1 个小时内接待了多少客户。常见的吞吐量指标有 QPS（Queries Per Second）、TPS（Transactions Per Second）和 BPS（Bits Per Second）。

- QPS，即查询数每秒，用于衡量一个系统每秒处理的查询数。这个指标通常用于读操作，越高说明对读操作的支持越好。所以，我们在设计一个分布式系统的时候，如果应用主要是读操作，那么需要重点考虑如何提高 QPS，来支持高频的读操作。
- TPS，即事务数每秒，用于衡量一个系统每秒处理的事务数。这个指标通常对应于写操作，越高说明对写操作的支持越好。我们在设计一个分布式系统的时候，如果应用主要是写操作，那么需要重点考虑如何提高 TPS，来支持高频写操作。
- BPS，即比特数每秒，用于衡量一个系统每秒处理的数据量。对于一些网络系统、数据管理系统，我们不能简单地按照请求数或事务数来衡量其性能。因为请求与请求、事务与事务之间也存在着很大的差异，比方说，有的事务大需要写入更多的数据。那么在这种情况下，BPS 更能客观地反应系统的吞吐量。

**响应时间**指的是，系统响应一个请求或输入需要花费的时间。响应时间直接影响到用户体验，对于时延敏感的业务非常重要。比如用户搜索导航，特别是用户边开车边搜索的时候，如果响应时间很长，就会直接导致用户走错路。

**完成时间**指的是，系统真正完成一个请求或处理需要花费的时间。任务并行（也叫作任务分布式）模式出现的其中一个目的，就是缩短整个任务的完成时间。特别是需要计算海量数据或处理大规模任务时，用户对完成时间的感受非常明显。

### 资源占用（Resource Usage）

资源占用指的是，一个系统提供正常能力需要占用的硬件资源，比如 CPU、内存、硬盘等。

一个系统在没有任何负载时的资源占用，叫做**空载资源占用**，体现了这个系统自身的资源占用情况。比如，你在手机上安装一个 App，安装的时候通常会提示你有多少 KB，这就是该 App 的空载硬盘资源占用。对于同样的功能，空载资源占用越少，说明系统设计越优秀，越容易被用户接受。

一个系统满额负载时的资源占用，叫做**满载资源占用**，体现了这个系统全力运行时占用资源的情况，也体现了系统的处理能力。同样的硬件配置上，运行的业务越多，资源占用越少，说明这个系统设计得越好。

### 可用性（Availability）

可用性，通常指的是系统在面对各种异常时可以正确提供服务的能力。可用性是分布式系统的一项重要指标，衡量了系统的鲁棒性，是系统容错能力的体现。

系统的可用性可以用**系统停止服务的时间与总的时间之比衡量。**假设一个网站总的运行时间是 24 小时，在 24 小时内，如果网站故障导致不可用的时间是 4 个小时，那么系统的可用性就是 4/24=0.167，也就是 0.167 的比例不可用，或者说 0.833 的比例可用。

除此之外，系统的可用性还可以用**某功能的失败次数与总的请求次数之比来衡量**，比如对网站请求 1000 次，其中有 10 次请求失败，那么可用性就是 99%。

你可能经常在一个系统的宣传语中见到或听到 3 个 9（或 3N，3 Nines）、5 个 9（或 9N，9 Nines）。这些宣传语中所说的 3 个 9、5 个 9，实际上就是系统厂商对可用性的一种标榜，表明该系统可以在 99.9% 或 99.999% 的时间里能对外无故障地提供服务。

讲到了可用性，你可能还会想到一个非常近似的术语：可靠性（Reliability）。那**可靠性和可用性有什么区别呢？**

**可靠性**通常用来表示一个系统完全不出故障的概率，更多地用在硬件领域。而**可用性**则更多的是指在允许部分组件失效的情况下，一个系统对外仍能正常提供服务的概率。

杰夫 · 迪恩（Jeff Dean）曾在 Google I/O 大会上透露：谷歌一个基于 1000 台通用计算机的集群，一年之内就有 1000+ 硬盘会出现故障。由于现在比较常见的分布式系统基本上都是基于通用计算机的，这就意味着在这些系统中无法实现真正的可靠，所以我们也会在一些场合见到可靠性和可用性交换使用的情况。

### 可扩展性（Scalability）

可扩展性，指的是分布式系统通过扩展集群机器规模提高系统性能 (吞吐、响应时间、 完成时间)、存储容量、计算能力的特性，是分布式系统的特有性质。  



分布式系统的设计初衷，就是利用集群多机的能力处理单机无法解决的问题。然而，完成某一具体任务所需要的机器数目，即集群规模，取决于单个机器的性能和任务的要求。

**当任务的需求随着具体业务不断提高时，除了升级系统的性能做垂直 / 纵向扩展外，另一个做法就是通过增加机器的方式去水平 / 横向扩展系统规模。**

这里垂直 / 纵向扩展指的是，增加单机的硬件能力，比如 CPU 增强、内存增大等；水平 / 横向扩展指的就是，增加计算机数量。好的分布式系统总在追求“线性扩展性”，也就是说系统的某一指标可以随着集群中的机器数量呈线性增长。

衡量系统可扩展性的常见指标是加速比（Speedup），也就是一个系统进行扩展后相对扩展前的性能提升。

- 如果你的扩展目标是为了提高系统吞吐量，则可以用扩展后和扩展前的系统吞吐量之比进行衡量。
- 如果你的目标是为了缩短完成时间，则可以用扩展前和扩展后的完成时间之比进行衡量。

### 不同场景下分布式系统的指标

我们都希望自己的分布式系统是高性能、高可用、高扩展和低资源占用的。但出于硬件成本、开发效率等因素的约束，我们无法在性能、可用性、可靠性和资源占用做到面面俱到。因此，在不同的业务场景中，设计者们需要有所取舍。

接下来，我带你一起看一下典型的电商、IoT、电信、HPC（高性能计算）、大数据、云计算、区块链等业务或系统对不同指标的诉求。

- **电商系统。**对于一个电商系统而言，系统设计者最看重的是吞吐量，为了处理更多的用户访问或订单业务，甚至不惜牺牲一些硬件成本。
- **IoT。**对于一个 IoT 系统而言，设计者最看重的是资源占用指标，因为在一些功能极简的 IoT 设备上 RAM、ROM 的可用资源通常都是 KB 级的。
- **电信业务。**对于电信业务而言，最重要的无疑是响应时间、完成时间，以及可用性。因为，你在打电话时不希望你的声音半天才被对方听到，也不希望半天才听到对方的回应，更不希望你的电话无法拨出。
- **HPC。**HPC 系统最显著的特点是任务执行时间极长，一个天体物理任务的分析和计算通常耗时数周甚至数月。因此，通过水平扩展来提高系统的加速比，是 HPC 系统设计者需要关注的。
- **大数据。**大数据任务的处理时间可能相对 HPC 系统来讲比较短，但常见的完成时间也达到了小时级，所以扩展性也是大数据系统首先要考虑的。
- **云计算。**对于一个云计算系统而言，常见任务是虚拟主机或容器的创建、资源调整、销毁等操作，如何减少这些操作的完成时间，从而提升用户体验是设计者们要重点关注的。另外，云计算系统本质上卖的是资源，那么降低系统本身的资源开销，也是系统设计的重中之重。
- **区块链。**区块链的吞吐量比较低，比特币的 TPS 只有 7 次每秒，单平均一次交易的确认就需要 10 分钟左右，因此吞吐量和完成时间通常是区块链系统设计者的首要目标。

![](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/20210426194213.jpg)

### 总结与思考

按照不同维度，分布式系统的指标可以分为性能、资源占用、可用性、可扩展性这四大类。我们自然希望自己的系统，是高性能、高可用、高扩展和低资源占用的，但考虑到硬件成本、开发效率等因素，必须要在设计不同的系统、业务时有所取舍。

所以，我又和你分析了典型的电商、IoT、电信、HPC（高性能计算）、大数据、云计算、区块链等业务或系统的不同诉求，进而得出了系统设计者需要关注哪些指标。你在设计其他类型的系统时，可以按照这个思路进行取舍。

我在文中提到了，分布式系统的指标之间会存在一些冲突或约束。那你不妨思考一下：我们今天讲解的指标中，哪些指标之间是相互制约、相互冲突的，它们又是如何制约的呢？

我是聂鹏程，感谢你的收听，欢迎你在评论区给我留言分享你的观点，也欢迎你把这篇文章分享给更多的朋友一起阅读。我们下期再会！

## 03 | 分布式互斥：有你没我，有我没你

通过前面的两篇文章，相信你已经对此次的分布式世界之行有了一个初步了解，想必对此次旅行也是充满期待。今天，我就带你正式踏上第一站：分布式协调与同步。在这一站，我将带你学习如何让分布在不同计算机上的程序具有“团队精神”，换句话说就是如何让程序通过协作共同去达成一个业务目标。

在本站，我将带你打卡的第一个景点是分布式互斥。那，什么是分布式互斥呢？

### 什么是分布式互斥？

想象一下，你正在一家餐厅使用自助咖啡机泡制咖啡，突然有个人过来挪走了你的杯子，开始泡制他自己的咖啡。你耐着性子等他操作完，继续泡制自己的咖啡。结果你开始没多久，他又回来中断了你泡制咖啡的过程。相信要不了几个回合，你和他就会上演一场“有你没我，有我没你”的格斗了。

这样现实的问题也同样存在于分布式世界。就像我们使用自助咖啡机时不希望被打扰一样，对于同一共享资源，一个程序正在使用的时候也不希望被其他程序打扰。这，就要求同一时刻只能有一个程序能够访问这种资源。

### 分布式锁

在分布式系统里，这种排他性的资源访问方式，叫作**分布式互斥**（Distributed Mutual Exclusion），而这种被互斥访问的共享资源就叫作**临界资源**（Critical Resource）。

接下来，我带你一起看看如何才能让分布式系统里的程序互斥地访问临界资源。

### 霸道总裁: 集中式算法

> 互斥算法，就是我们所说的**集中式算法**，也可以叫做中央服务器算法。
>
> 协调者

对于前面提到的咖啡机问题，我们首先想到的就是，增加一个“协调者”来约束大家使用自助咖啡机，解决强行插入打断别人的问题。

类似地，我们引入一个协调者程序，得到一个分布式互斥算法。每个程序在需要访问临界资源时，先给协调者发送一个请求。如果当前没有程序使用这个资源，协调者直接授权请求程序访问；否则，按照先来后到的顺序为请求程序“排一个号”。如果有程序使用完资源，则通知协调者，协调者从“排号”的队列里取出排在最前面的请求，并给它发送授权消息。拿到授权消息的程序，可以直接去访问临界资源。

这个互斥算法，就是我们所说的**集中式算法**，也可以叫做中央服务器算法。之所以这么称呼，是因为协调者代表着集中程序或中央服务器。

集中式算法的示意图如下所示:

![](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/20210426194218.jpg)

如图所示，程序 1、2、3、4 为普通运行程序，另一个程序为协调者。当程序 2 和程序 4 需要使用临界资源时，它们会向协调者发起申请，请求协调者授权。

不巧的是，程序 3 正在使用临界资源。这时，协调者根据程序 2 和 4 的申请时间顺序，依次将它们放入等待队列。在这个案例里，程序 4 的申请时间早于程序 2，因此排在程序 2 的前面。

程序 3 使用完临界资源后，通知协调者释放授权。此时，协调者从等待队列中取出程序 4，并给它发放授权。这时，程序 4 就可以使用临界资源了。

从上述流程可以看出，**一个程序完成一次临界资源访问，需要如下几个流程和消息交互**：

1. 向协调者发送请求授权信息，1 次消息交互；
2. 协调者向程序发放授权信息，1 次消息交互；
3. 程序使用完临界资源后，向协调者发送释放授权，1 次消息交互。

因此，每个程序完成一次临界资源访问，需要进行 3 次消息交互。

不难看出，集中式算法的优点在于直观、简单、信息交互量少、易于实现，并且所有程序只需和协调者通信，程序之间无需通信。但是，这个算法的问题也出在了协调者身上。

- 一方面，协调者会成为系统的性能瓶颈。想象一下，如果有 100 个程序要访问临界资源，那么协调者要处理 100*3=300 条消息。也就是说，协调者处理的消息数量会随着需要访问临界资源的程序数量线性增加。
- 另一方面，容易引发单点故障问题。协调者故障，会导致所有的程序均无法访问临界资源，导致整个系统不可用。

因此，在使用集中式算法的时候，一定要选择性能好、可靠性高的服务器来运行协调者。

**小结一下：**集中式算法具有简单、易于实现的特点，但可用性、性能易受协调者影响。在可靠性和性能有一定保障的情况下，比如中央服务器计算能力强、性能高、故障率低，或者中央服务器进行了主备备份，主故障后备可以立马升为主，且数据可恢复的情况下，集中式算法可以适用于比较广泛的应用场景。

### 民主协商：分布式算法

既然引入协调者会带来一些问题，这时你可能就会想，不用协调者是否可以实现对临界资源的互斥访问呢？想象一下，当你需要使用自助咖啡机的时候，是不是可以先去征求其他人的意见，在确认其他人都没在使用也暂时不会使用咖啡机时，你就可以放心大胆地去泡制自己的咖啡了呢？

同理，我们可以把这套算法用于分布式系统。当一个程序要访问临界资源时，先向系统中的其他程序发送一条请求消息，在接收到所有程序返回的同意消息后，才可以访问临界资源。其中，请求消息需要包含所请求的资源、请求者的 ID，以及发起请求的时间。

这，就是民主协商法。**在分布式领域中，我们称之为分布式算法，或者使用组播和逻辑时钟的算法。**

如图所示，程序 1、2、3 需要访问共享资源 A。在时间戳为 8 的时刻，程序 1 想要使用资源 A，于是向程序 2 和 3 发起使用资源 A 的申请，希望得到它们的同意。在时间戳为 12 的时刻，程序 3 想要使用资源 A，于是向程序 1 和 2 发起访问资源 A 的请求。

### 轮值 CEO：令牌环算法 

那么除了集中式算法、分布式算法以外，还有什么方法可以实现分布式互斥吗？答案是肯定的。毕竟，方法总比问题多。华为独创的轮值 CEO 其实就给了我们一个很好的启示。在华为的轮值 CEO 体系里，CEO 就是临界资源，同时只能有一个人担任，由多名高管轮流出任 CEO。

类似地，程序访问临界资源问题也可按照轮值 CEO 的思路实现。 如下图所示，所有程序构成一个环结构，令牌按照顺时针（或逆时针）方向在程序之间传递，收到令牌的程序有权访问临界资源，访问完成后将令牌传送到下一个程序；若该程序不需要访问临界资源，则直接把令牌传送给下一个程序。

在分布式领域，这个算法叫作令牌环算法，也可以叫作基于环的算法。为了便于理解与记忆，你完全可以把这个方法形象地理解为轮值 CEO 法。

![令牌环算法](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/20210426194223.jpg)

因为在使用临界资源前，不需要像分布式算法那样挨个征求其他程序的意见了，所以相对而言，在令牌环算法里单个程序具有更高的通信效率。同时，在一个周期内，每个程序都能访问到临界资源，因此令牌环算法的公平性很好。

但是，不管环中的程序是否想要访问资源，都需要接收并传递令牌，所以也会带来一些无效通信。假设系统中有 100 个程序，那么程序 1 访问完资源后，即使其它 99 个程序不需要访问，也必须要等令牌在其他 99 个程序传递完后，才能重新访问资源，这就降低了系统的实时性。

综上，**令牌环算法非常适合通信模式为令牌环方式的分布式系统**，例如移动自组织网络系统。一个典型的应用场景就是无人机通信。

无人机在通信时，工作原理类似于对讲机，同一时刻只能发送信息或接收信息。因此，通信中的上行链路（即向外发送信息的通信渠道）是临界资源。

如下图所示，所有的无人机组成一个环，按照顺时针方向通信。每个无人机只知道其前一个发送信息的无人机，和后一个将要接收信息的无人机。拥有令牌的无人机可以向外发送信息，其他无人机只能接收数据。拥有令牌的无人机通信完成后，会将令牌传送给后一个无人机。

所有的无人机轮流通信并传输数据，从而消除了多个无人机对通信资源的争夺，使得每个无人机都能接收到其他无人机的信息，降低了通信碰撞导致的丢包率，保证了网络通信的稳定性，提高了多个无人机之间的协作效率。



# **高并发**

## 基础概念

并发: 

常见的并发方式 : 多线程, 子进程, 协程, 生成器. 多进程

### 需要避免的问题

全局变量引发的竞争问题

# 线程通信

# 进程通信

# **云计算**

### 定义



云计算（cloud computing）是分布式计算的一种，指的是通过网络“云”将巨大的数据计算处理程序分解成无数个小程序，然后，通过多部服务器组成的系统进行处理和分析这些小程序得到结果并返回给用户。

> 数据分割 使用相同的程序代码, 来跑同一个任务

云计算早期，简单地说，就是简单的分布式计算，解决任务分发，并进行计算结果的合并。因而，云计算又称为网格计算。通过这项技术，可以在很短的时间内（几秒种）完成对数以万计的数据的处理，从而达到强大的网络服务。

现阶段所说的云服务已经不单单是一种分布式计算，而是**分布式计算**、**效用计算**、**负载均衡**、并行计算、网络存储、热备份冗杂和虚拟化等计算机技术混合演进并跃升的结果。



维基百科:

**云计算**（英语：**cloud computing**），是一种基于[互联网](https://zh.wikipedia.org/wiki/互联网)的计算方式，通过这种方式，共享的软硬件资源和信息可以按需求提供给计算机各种终端和其他设备，使用服务商提供的计算机基建作计算和资源。

# Web开发技术原理

本文档主要用于记录 **说明简介** , **技术参考** 和 **使用说明**, **工作原理** 以及 **运行机制**

更倾向于理论化和抽象化

# 网络基础

计算机网络

## 服务器开发



## 技术趋势

- 快速迭代
- **高并发**
  - 异步编程(上下文切换)
- 分布式
- 高可用
- 高性能
- **实时数据处理**
- 高扩展
- 快速响应
- 微服务系统
- 性能优化性能调优

## 核心必会技术

- Ajax
- mysql
- linux
- 框架



# 基本概念

- **网络编程**: 通过编写程序,实现不同的电脑上的软件能够进行数据传递,进程之间的通信
- **学习目的**: 编写基于网络通讯的软件
- **网络**: 一些相互连接的以共享资源为目的的计算机(客户机和服务器等网络设备)的集合,使用网络能够把多方连接在一起,然后可以进行数据传递
- 今后所有编写的程序几乎都是基于网络
- 网络的本质是数据的传输,连通多方然后进行通信(数据的单向传输,双向传输)
- **软件的核心是网络，硬件的核心是CPU**
- 使用网络能把多方联结在一起,然后可以进行数据传递

## IP地址

互联网协议地址Internet Protocol Address 网际协议地址
ip地址两部分组成: 网络号 + 主机号

> 地址就是用来标记地点的
> **MAC地址**: 物理地址 是唯一的
> IP地址包括两个部分: 网络地址 和 主机地址

### IP地址的作用

用来在网络中标记一台电脑,是网路设备为网络的 每台计算机分配的一个唯一标识. 

#### 公网Ip

[公网IP查询](https://ifconfig.me)
[直接显示IP](<https://ifconfig.me/ip>)

#### 私有IP

在这么多网络IP中，国际规定有一部分IP地址是用于我们的局域网使用，也就是属于私网IP，不在公网中使用的，它们的范围是：
10.0.0.0 ~ 10.255.255.255(虚拟机)
172.16.0.0～172.31.255.255

192.168.0.0～192.168.255.255

**回路测试**: IP地址
127．000．000．001~
127．255．255．255用于回路测试
广域网Ip的地址每天都会变的

#### 本机地址

**特殊的IP地址**: 127.0.0.1可以代表本机IP地址，用http://127.0.0.1就可以测试本机中配置的Web服务器。
**特殊的域名**: localhost

> localhost 是本机域名 用来解析到 本机127.0.0.1 ip地址上
> 本机的软件之间通讯
> 路由器的作用 记录IP 记录mac地址 记录局域网ip对应信息 
> 局域网IP:
> **DNS服务器**  

#### IPv4 和 IPv6

ipv4 10进制
ipv6 16进制

## 端口 (port)

#### 端口的概念

端口: 分为**物理端口**和**逻辑端口**,网络中的端口为逻辑端口

如果一个程序需要收发网络数据，那么就需要有这样的端口在linux系统中，端口可以有65536（2^16）个之多！
既然有这么多，操作系统为了统一管理，所以进行了编号，这就是端口号
本地操作系统会给那些有需求的**进程**分配**协议端口**（**protocal port**，即我们常说的**端口**），每个协议端口由一个**正整数标识**，如：80，139等等。
当目的主机接收到数据报后，将根据报文首部的目的端口号，把数据发送到相应端口，而与此**端口**相**对应**的那个**进程**将会领取数据并等待下一组数据的到来。

**端口号**: 端口是通过端口号来标记的，端口号只有整数，范围是从0到65535
端口其实就是队，操作系统为各个进程分配了不同的队，数据报按照目的端口被推入相应的队中，等待被进程取用，在极特殊的情况下，这个队也是有可能溢出的，不过操作系统允许各进程指定和调整自己的队的大小。
不光接受数据报的进程需要开启它自己的端口，发送数据报的进程也需要开启端口，这样，数据报中将会标识有源端口，以便接受方能顺利的回传数据报到这个端口。

端口号不是随意使用的，而是按照一定的规定进行分配。端口的分类标准有好几种，我们这里不做详细讲解，只介绍一下知名端口和动态端口

**知名端口**: (Well Known Ports)是众所周知的端口号，范围从0到1023

- 80端口分配给HTTP服务
- 21端口分配给FTP服务
- 22端口分配给SSH服务
- 25端口分配给SMTP服务

一般情况下，如果一个程序需要使用知名端口的需要有root权限
**动态端口**:(Dynamic Ports) 范围是从1024到65535  一般不固定分配某种服务,而是动态分配. 

动态分配是指当一个系统程序或应用程序程序需要网络通信时，它向主机申请一个端口，主机从可用的端口号中分配一个供它使用。
当这个程序关闭时，同时也就释放了所占用的端口号

**端口不是一一对应的**，电脑作为客户机访问HTTP服务器时，服务器的端口为80与客户机通信，但客户机则可能使用的是3457端口。

#### 端口的作用

一台拥有IP地址的主机可以提供许多服务，比如Web服务，FTP服务、SMTP服务等，这些服务完全可以通过1个IP地址来实现。
那么，主机是怎样区分不同的网络服务呢？显然不能只靠IP地址，因为IP地址与网络服务的关系是一对多的关系。
实际上是通过"**IP地址+端口号**"来**区分**不同的**服务**的。
客户端通常对它所使用的端口号并不关心，只需保证该端口号在本机上是唯一的就可以了。
**客户端端口号**又称作临时端口号（即存在时间很短）。
这是因为它通常只是在用户运行该客户程序时才存在，而服务器则只要主机开着，其服务就运行。

 

#### 创建 Socket

**套接字使用流程**: 

1. 创建套接字
2. 使用套接字收/发数据
3. 关闭套接字

# 网络传输协议

[网络传输协议](https://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE)

# ARP协议

**地址解析协议**（英语：**A**ddress **R**esolution **P**rotocol，缩写：**ARP**）是一个通过解析[网络层](https://zh.wikipedia.org/wiki/网络层)地址来找寻[数据链路层](https://zh.wikipedia.org/wiki/数据链路层)地址的[网络传输协议](https://zh.wikipedia.org/wiki/网络传输协议)，它在[IPv4](https://zh.wikipedia.org/wiki/IPv4)中极其重要。ARP最初在1982年的[RFC](https://zh.wikipedia.org/wiki/RFC) [826](https://tools.ietf.org/html/rfc826)（征求意见稿）[[1\]](https://zh.wikipedia.org/wiki/地址解析协议#cite_note-1)中提出并纳入[互联网标准](https://zh.wikipedia.org/wiki/互联网标准) STD 37. **ARP** 也可能指是在多数[操作系统](https://zh.wikipedia.org/wiki/操作系统)中管理其相关地址的一个进程。

ARP是通过[网络地址](https://zh.wikipedia.org/wiki/網路位址)来定位[MAC地址](https://zh.wikipedia.org/wiki/MAC地址)。 ARP已经在很多网路层和数据链接层之间得以实现，包括IPv4，[Chaosnet](https://zh.wikipedia.org/w/index.php?title=Chaosnet&action=edit&redlink=1), [DECnet](https://zh.wikipedia.org/w/index.php?title=DECnet&action=edit&redlink=1)和Xerox [PARC Universal Packet](https://zh.wikipedia.org/w/index.php?title=PARC_Universal_Packet&action=edit&redlink=1)（PUP）使用[IEEE 802](https://zh.wikipedia.org/wiki/IEEE_802)标准, [光纤分布式数据接口](https://zh.wikipedia.org/wiki/光纤分布式数据接口), [X.25](https://zh.wikipedia.org/wiki/X.25), [帧中继](https://zh.wikipedia.org/wiki/帧中继)和[异步传输模式](https://zh.wikipedia.org/wiki/异步传输模式)（ATM），[IEEE 802.3](https://zh.wikipedia.org/wiki/IEEE_802.3)和[IEEE 802.11](https://zh.wikipedia.org/wiki/IEEE_802.11)标准上[IPv4](https://zh.wikipedia.org/wiki/IPv4)占了多数流量。

在[IPv6](https://zh.wikipedia.org/wiki/IPv6)中[邻居发现协议](https://zh.wikipedia.org/wiki/邻居发现协议)（NDP）用于代替地址解析协议（ARP）。

# NDP协议

[ndp协议](https://zh.wikipedia.org/wiki/%E9%82%BB%E5%B1%85%E5%8F%91%E7%8E%B0%E5%8D%8F%E8%AE%AE)



# TCP协议

## UDP网络程序 - 发送数据

> 核心步骤
>
> 1. 导入socket模块
> 2. 创建socket对象    (UDP类型)
> 3. 发送数据
> 4. 关闭socket对象

```python
# 导入模块
import socket
# 创建模块
udp_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
# 发送数据('数据,编码', ('ip','端口号'))  必须以元组的形式
udp_socket.sendto("约吗?".encode=(), ("192.168.150.30", 8080))
# 关闭socket对象
udp_socket.close()
# 接收端开启网络调试助手
# 设置协议方式
# 设置IP地址
# 设置端口
# 连接网络
```

## UDP协议 

> 碎片化处理视频技术  补包
> 热备份技术 不用实时同步

### 概念

User Datagram Protocol (用户数据报协议) **面向无连接型**

### 特点

整体上: **简单高效**,**传输速度特别快**

- 包总量较少的通信(DNS)
- 视频, 音频等多媒体通信(即时通信)
- 限定于LAN等特定网络中的应用通信
- 广播通信(广播, 多播)

**缺点**

- 不安全
- 可能数据丢失

### 作用

UDP协议的主要作用是将网络数据流量压缩成数据包的形式。一个典型的数据包就是一个二进制数据的传输单位。每一个数据包的前8个字节用来包含报头信息，剩余字节则用来包含具体的传输数据。

## TCP协议

### 概念

> 面试经常问:
> **三次握手**
> **四次挥手**
>
> > tcp通行需要经过 创建连接, 数据传输,终止连接 是哪个步骤
> >
> > tcp是可靠传输的原因
> >
> > 1. 发送应答机制
> > 2. 超时重传
> > 3. 错误校验
> > 4. 流量控制和阻塞管理

TCP协议: Transmission Control Protocol(传输控制协议)是一种面向连接的, 可靠的, 基于字节流的传输层通信协议

TCP 通信需要经过 **创建连接**, **数据传输**, **终止连接**三个步骤
TCP 提供一种面向连接的通信服务,只有在确认通信对端存在时才会收发数据

### TCP特点

> 延伸
> 全双工模式 
> 单工模式
> 半双工模式 不能同时传输

1. **面向连接**
   通信双方必须**先建立连接**才能进行数据的**传输**，双方都必须为该连接分配必要的**系统内核资源**，以管理连接的状态和连接上的传输。
   双方间的数据传输都可以通过这一个连接进行。
   完成数据交换后，双方必须断开此连接，以释放系统资源。
   这种**连接是一对一的**，因此TCP不适用于广播的应用程序，基于广播的应用程序请使用UDP协议。

2. **可靠传输**

   1. **TCP采用发送应答机制**

   TCP发送的每个报文段都必须得到接收方的应答才认为这个TCP报文段传输成功

   2. **超时重传** 

   发送端发出一个报文段之后就**启动定时器**，如果在定时时间内**没有收到应答**就重新发送这个报文段。

TCP为了保证不发生丢包，就给每个包一个序号，同时序号也保证了传送到接收端实体的包的按序接收。然后接收端实体对已成功收到的包发回一个相应的确认（ACK）；如果发送端实体在合     理的往返时延（RTT）内未收到确认，那么对应的数据包就被假设为已丢失将会被进行重传。
    

3. **错误校验**

TCP用一个校验和函数来检验数据是否有错误；在发送和接收时都要计算校验和。
    

4. **流量控制和阻塞管理**

   流量控制用来避免主机发送得过快而使接收方来不及完全收下。



## TCP与UDP的不同点

- 面向连接(三次握手)
- 有序数据传输
- 重发丢失的数据包
- 舍弃重复的数据
- 无差错的数据传输
- 阻塞/流量控制

**现代互联网中TCP/IP协议的应用场景更广泛,更安全更可靠**

## TCP通信模型

通讯开始之前, 一定要先建立相关的连接,才能 发送数据

## TCP网络编程-客户端

tcp的客户端要比服务器端简单很多

```python
# 从 socket 导入 函数和功能
from socket import *

# 创建 socket
tcp_client_socket = socket(AF_INET,SOCK_STREAM)

# 目的信息
server_ip = input("请输入服务ip")
server_port = int(input('请输入服务器port: '))

# 连接服务器 发起连接请求
tcp_client_socket.connect((server_ip, server_port))

# 提示用户输数据
print('连接成功!可以发送数据了')
send_data = input("请输入要发送的数据:")
tcp_client_socket.send(send_data.encode('utf-8'))

# 接收对方发过来的数据,最大接收1024个字节

recv_data = tcp_client_socket.recv(1024)
print('接收到的数据为: ', recv_data.decode('gbk'))

# 关闭 socket
tcp_client_socket.close()

```

## TCP网络编程-服务器

代码示例

```python
import socket
# 创建服务器socket
tcp_server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
# 绑定端口
tcp_server_socket.bind(('',7891))
# socket进入监听状态
# backlog：等待连接队列的最大长度。最大可监听数
tcp_server_socket.listen(128)
# 监听到消息后,接收对方信息  标记该套接字以方便以后使用
client_socket, addr = tcp_server_socket.accept()
print('客户端的IP地址是', addr[0])
client_socket.send('我是吴方圆,是个小哥哥^_^'.encode('utf-8'))
recv_data = client_socket.recv(1024)
print('接收到的数据是: ',recv_data.decode('gbk'))
# 关闭连接的套接字
client_socket.close()
# 关闭主套接字
tcp_server_socket.close()

```

## TCP注意点

1. **tcp服务器**一般情况下都需要**绑定**，否则客户端找不到这个服务器
2. **tcp客户端**一般不绑定，因为是**主动链接服务器**，所以只要确定好服务器的ip、port等信息就好，本地客户端可以随机
3. **tcp服务器**中通过**listen**可以将socket创建出来的主动套接字变为被动套接字，这是做tcp服务器时必须要做的
4. 当客户端需要链接服务器时，就需要使用**connect进行连接**，udp是不需要链接的而是直接发送，但是tcp必须先链接，只有链接成功才能通信
5. 当一个**tcp客户端** **接服务器**时，服务器端会有1个**新的套接字**，这个套接字用来**标记**这个**客户端**，单独为这个客户端服务
6. **listen后的套接字是被动套接字**，用来接收新的客户端的链接请求的，而accept返回的新套接字是标记这个新客户端的
7. 关闭listen后的套接字意味着被动套接字关闭了，会导致新的客户端不能够链接服务器，但是之前已经链接成功的客户端正常通信。
8. 关闭accept返回的套接字意味着这个客户端已经服务完毕
9. 当客户端的套接字调用close后，服务器端会recv解堵塞，并且返回的长度为0，(**发出关闭服务器信号,不再要接收数据**)度来区别客户端是否已经下线

## 案例: 文件下载器 没看 (补充看后面)







# miniweb框架

## 学习目标

> 静态资源
> 动态资源
> web服务器的作用:web服务器主要是接收⽤户浏览器的请求,根据⽤户的资源请求返回不同的资源. 
> 路由的作用
> 浏览器从请求到显示动态页面的过程
> web开发一般使用成熟的开发框架
> 框架开发思路
> 模块开发思路

## 框架和WEB服务器的关系

前面已经学习过web服务器,我们知道web服务器主要是接收⽤户浏览器的请求,根据⽤户的资源请求返回不同的资源.

框架: 封装了很多工具类 ,利用这些工具包(框架)直接用会极大的提高开发效率, 减少重复干的事情

(Web应用程序 - 模板 - 数据库)模型

## 重要概念

### 静态资源

一旦准备好资源,**不再需要经常变化的资源**, 往往是固定不变的资源. 由于该资源不需要经常变化,所以可以提前准备. 比如png/jpg/css/js等文件

### 动态资源(生成资源)

　    和静态资源相反, 这种**资源会经常变化**.比如,我们要编写一个电商网站, 我们无法预测用户在浏览商品时选择什么样的条件.
　　根据用户选择条件不同, 我们给用户提供可供选择的商品就不同. 这种资源⽆法提前准备.

### 模板文件(结构 - 容器) 

​	在用户搜索各种商品的时候,大家是否发现 虽然大家的条件不同,但是显示商品的网页中除了那些商品信息 整个网页的结构/布局几乎是一模一样的.
　　而模板文件是网页中通用的结构构成的⼀个页面. 这个页面中不含有任何用户需要查看的数据,当用户查询数据的时候会将最终的结果放到模板中形成⽤户真正需要的页面. 
　　这就好比, 生活中⼀个毛坯房可以装饰上不同的风格. 		我们把模板文件转化为 用户真正看到的网页的过程就称为**模板替换**.

### 通信规范

服务器和浏览器之间通信使用HTTP协议

 框架和web服务器之间进行通信也需要一个协议

> 服务器的作用
> 接受客户端请求
> 响应客户端请求
> 调用应用框架获取
> 调用应用框架获取

## 基础框架构建

> 实现访问`.py` 文件 和访问 `.html` 访问不同的内容

## 路由列表(Django)

> 路由的作用
>
> 路由列表配置(路由字典)

根据不同的请求给出不同的响应

路由概念: web后台程序非常重要的一个特点. **路由根据用户的请求, 选择对应的函数来处理相应的请求.** 

## 装饰器路由(flask)

> 使用装饰器路由自动添加路径数据

装饰器路由: 使用装饰器工厂函数接收路径参数, 进而实现装饰器路由

## 模板替换

> 模板替换的具体步骤

使用正则表达式替换内容替换

## JWT - json web token

在用户注册或登录后, 我们想记录用户的登录状态, 或者为用户创建身份认证的凭证. 不推荐使用Session认证机制, 而是使用 Json Web Token 认证机制

涉及到前后端分离时, 一般不采用session / cookie机制, 采用token机制

cookie仅仅在浏览器中有效, APP不能使用cookie

### 什么是JWT

Json web token (JWT), 是为了在网络应用环境间传递声明而执行的一种基于JSON的开放标准（(RFC 7519).该token被设计为紧凑且安全的，特别适用于分布式站点的单点登录（SSO）场景。JWT的声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源，也可以增加一些额外的其它业务逻辑所必须的声明信息，该token也可直接被用于认证，也可被加密。



### token认证和session认证的区别

#### session认证

HTTP协议本事是一种无状态协议. 为了让应用识别出是哪个用户发出的请求, 只能在服务器存储一份用户登录的信息, 这份登录信息会在响应时传递给浏览器, 告诉其保存为cookie, 以便下次请求时发送给服务器应用, 这样就能识别请求来自哪个用户了, 这就是传统的基于session认证.

但是这种基于session的认证使应用本身很难得到扩展, 随着不同客户端用户的增加, 独立的服务器已无法承载更多的用户, 这时候基于session认证应用的问题就会暴露出来

#### session认证存在的问题

**Session**: 每个用户经过我们的应用认证之后，我们的应用都要在服务端做一次记录，以方便用户下次请求的鉴别，通常而言session都是保存在内存中，而随着认证用户的增多，服务端的开销会明显增大。

**扩展性**: 用户认证之后，服务端做认证记录，如果认证的记录被保存在内存中的话，这意味着用户下次请求还必须要请求在这台服务器上,这样才能拿到授权的资源，这样在分布式的应用上，相应的限制了负载均衡器的能力。这也意味着限制了应用的扩展能力。  **扩展性差,session数据如果存在某台服务器,下次访问还得再那台服务器上访问拿取数据, 因此分布式服务器采用Token机制认证**

**CSRF**: 因为是基于cookie来进行用户识别的, cookie如果被截获，用户就会很容易受到**跨站请求伪造**的攻击。

### 基于token的鉴权机制(类似协议)

基于token的鉴权机制类似于http协议也是无状态的，它不需要在服务端去保留用户的认证信息或者会话信息。这就意味着基于token认证机制的应用不需要去考虑用户在哪一台服务器登录了，这就为应用的扩展提供了便利。

流程上是这样的：

- 用户使用用户名密码来请求服务器
- 服务器进行验证用户的信息
- 服务器通过验证发送给用户一个token
- 客户端存储token，并在每次请求时附送上这个token值
- 服务端验证token值，并返回数据

这个token必须要在每次请求时传递给服务端，它应该保存在请求头里， 另外，服务端要支持CORS(跨来源资源共享)策略，一般我们在服务端这么做就可以了Access-Control-Allow-Origin: *。

那么我们现在回到JWT的主题上。

### JWT介绍

JWT是由三段信息构成的，将这三段信息文本用 `.` 链接一起就构成了JWT字符串。

第一部分我们称它为头部 - `header` , 第二部分我们称其为载荷 - `payload` ，第三部分是签证 `signature` .

#### **header**: 声明信息

头部承载两部分信息: 声明类型为 `JWT` , 声明加密的算法- algorithm, 通常直接使用 HMAC SHA256

```json
# 原生信息
{
	'type': 'JWT',
	'alg':'HS256',
}
# 加密后信息, 采用base64加密后, 构成了第一部分.
eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9


```

#### **playload**

载荷就是存放有效信息的地方。这个名字像是特指飞机上承载的货品，这些有效信息包含三个部分

- 标准中注册的声明
- 公共的声明
- 私有的声明

**标准中注册的声明** (建议但不强制使用) ：

- **iss**: jwt签发者
- **sub**: jwt所面向的用户
- **aud**: 接收jwt的一方
- **exp**: jwt的过期时间，这个过期时间必须要大于签发时间
- **nbf**: 定义在什么时间之前，该jwt都是不可用的.
- **iat**: jwt的签发时间
- **jti**: jwt的唯一身份标识，主要用来作为一次性token,从而回避重放攻击。

**公共的声明** ： 公共的声明可以添加任何的信息，一般添加用户的相关信息或其他业务需要的必要信息.但不建议添加敏感信息，因为该部分在客户端可解密.

**私有的声明** ： 私有声明是提供者和消费者所共同定义的声明，一般不建议存放敏感信息，因为base64是对称解密的，意味着该部分信息可以归类为明文信息。

定义一个payload:

```json
{
  "sub": "1234567890",
  "name": "John Doe",
  "admin": true
}
```

然后将其进行base64加密，得到JWT的第二部分。

```
eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9
```

#### **signature**

JWT的第三部分是一个签证信息，这个签证信息由三部分组成：

- header (base64后的)
- payload (base64后的)
- secret

这个部分需要base64加密后的header和base64加密后的payload使用`.`连接组成的字符串，然后通过header中声明的加密方式进行**加盐**`secret`组合加密，然后就构成了jwt的第三部分。

```javascript
// javascript
var encodedString = base64UrlEncode(header) + '.' + base64UrlEncode(payload);

var signature = HMACSHA256(encodedString, 'secret'); // TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ
```

将这三部分用`.`连接成一个完整的字符串,构成了最终的jwt:

```
eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ
```

**注意：secret是保存在服务器端的，jwt的签发生成也是在服务器端的，secret就是用来进行jwt的签发和jwt的验证，所以，它就是你服务端的私钥，在任何场景都不应该流露出去。一旦客户端得知这个secret, 那就意味着客户端是可以自我签发jwt了。**

### 如何应用

一般是在请求头里加入`Authorization`，并加上`Bearer`标注：

```
fetch('api/user/1', {
  headers: {
    'Authorization': 'Bearer ' + token
  }
})
```

服务端会验证token，如果验证通过就会返回相应的资源。整个流程就是这样的:

![jwt](https://wwfyde.oss-cn-hangzhou.aliyuncs.com/images/20210426194234.png)

服务端负责签发token和校验token, 服务端并不存储任何用户信息



验证原理:

```
拿取签名 中的 第一 第二个部分 + secret+ 进行计算 得到一个签名值(signature) 如果与 JWT 的签名值一样就验证通过 这意味着对JWT进行篡改是无意义的
```

djangorestframework-jwt 的作用: 帮助 签发 帮助验证, 但是用户名密码的校验不是由它完成的, 是由Django认证系统来完成的

### 总结

### JWT

- 一种token认证机制
- 也有过期时间
- 本质是包含3个部分用点式连接的的字符串
- 签发时间点: 注册完成后和登录时

#### 优点

- **跨语言支持**, 因为json的通用性，所以JWT是可以进行跨语言支持的，像JAVA,JavaScript,NodeJS,PHP等很多语言都可以使用。
- 因为有了payload部分，所以JWT可以在自身存储一些其他业务逻辑所必要的非敏感信息。
- **便于传输**，jwt的构成非常简单，字节占用很小，所以它是非常便于传输的。
- **易于扩展**, 它不需要在服务端保存会话信息, 所以它易于应用的扩展
- 浏览器不支持cookie, 网页, APP均可用, 更加安全

#### 安全相关

- 不应该在jwt的payload部分存放敏感信息，因为该部分是客户端可解密的部分(用户原始密码一定不能放)。
- 保护好secret私钥，该私钥非常重要。
- 如果可以，请使用https协议

### JWT使用

安装

pip install djangorestframework-jwt



## 分布式系统

> 应用场景: 分布式计算(distributed computation), 分布式存储(distributed storage)
>
> 相关概念: 主从同步, 集群, 负载均衡

### 说明简介

分布式系统是由一组通过网络进行通信、为了完成共同的任务而协调工作的计算机节点组成的系统。分布式系统的出现是为了用廉价的、普通的机器完成单个计算机无法完成的计算、存储任务。其目的是**利用更多的机器，处理更多的数据**。

### 作用特点

### 原理机制

# celery

参考商城项目 - 第二天 - [celery](file:///D:\python就业班19版\05-项目-美多商城-10天\02-北京Python就业班29期-美多商城项目-第02天\1-教学资料\celery\index.html)

### 说明简介

异步任务框架

生产者 - 消费者模型

任务(task) - 任务队列(broker) - **多**处理任务(worker)

# FastDFS - 分布式文件系统

FastDFS 分布式文件系统	

# GraphQL

QraphQL for Python

QraphQL for Django

# Kafka

Apache Kafka是一款开源的消息引擎系统(Messaging System消息队列, 消息中间件)

系统A发送消息给消息引擎系统，系统B从消息引擎系统中读取A发送的消息。

- 消息引擎传输的对象是消息；
- 如何传输消息属于消息引擎设计机制的一部分。

既然消息引擎是用于在不同系统之间传输消息的，那么如何设计待传输消息的格式从来都是一等一的大事。

Kafka的选择：它使用的是纯二进制的字节序列。当然消息还是结构化的，只是在使用之前都要将其转换成二进制的字节序列

消息设计出来之后还不够，消息引擎系统还要设定具体的传输协议，即我用什么方法把消息传输出去。常见
的有两种方法：

- 点对点模型：也叫消息队列模型。如果拿上面那个“民间版”的定义来说，那么系统A发送的消息只能被
  系统B接收，其他任何系统都不能读取A发送的消息。日常生活的例子比如电话客服就属于这种模型：同
  一个客户呼入电话只能被一位客服人员处理，第二个客服人员不能为该客户服务。
- 发布/订阅模型：与上面不同的是，它有一个主题（Topic）的概念，你可以理解成逻辑语义相近的消息容器。该模型也有发送方和接收方，只不过提法不同。发送方也称为发布者（Publisher），接收方称为订阅者（Subscriber）。和点对点模型不同的是，这个模型可能存在多个发布者向相同的主题发送消息，而订阅者也可能存在多个，它们都能接收到相同主题的消息。生活中的报纸订阅就是一种典型的发布/订阅模型

比较酷的是Kafka同时支持这两种消息引擎模型，专栏后面我会分享Kafka是如何做到这一点的。

(主从,不推荐master-slave)Leader-Follower







# 设计模式

软件设计模式 分为 设计模式, 架构模式, 函数式, 并行模式等

设计模式, 编程方法论





钩子函数

